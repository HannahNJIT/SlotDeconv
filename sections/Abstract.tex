\begin{abstract}
\textbf{Motivation:} Spatial transcriptomics enables spatially resolved gene expression profiling, yet sequencing-based platforms capture multi-cell mixtures per spot, necessitating computational deconvolution. Existing approaches often rely on fixed reference signatures or learn them without explicit separability constraints, yielding ill-conditioned linear systems when closely related subtypes exhibit highly similar expression profiles. Moreover, many methods treat spots independently, ignoring the spatial autocorrelation inherent to tissue architecture.

\textbf{Results:} We present SlotDeconv, a three-stage framework that decouples nonlinear signature learning from linear mixture inference for robust proportion estimation. Stage~1 learns discriminative cell-type signatures via learnable prototype vectors (``slots'') decoded through a neural network under a negative binomial likelihood. A max-margin diversity loss explicitly penalizes inter-signature cosine similarity, improving separability even among fine-grained subtypes within the same lineage. Stage~2 initializes proportions via discriminative-gene-weighted nonnegative least squares (NNLS), leveraging the stabilized linear system induced by the learned signatures. Stage~3 refines proportions by minimizing the KL divergence between empirical per-spot gene distributions and normalized reconstructions, together with Gaussian-kernel neighborhood consistency on the proportion matrix. On a mouse brain ST dataset with 27 cell types, SlotDeconv achieves a spot-wise Pearson correlation of 0.55, a 29\% relative improvement over baseline NNLS (0.43), with particularly strong gains in resolving highly similar cortical-layer neuronal subtypes. We use ``slots'' to denote learnable prototypes; unlike Slot Attention, we do not employ iterative attention-based binding.

\textbf{Availability:} Source code is available at \url{https://github.com/xxx/SlotDeconv}.
\end{abstract}